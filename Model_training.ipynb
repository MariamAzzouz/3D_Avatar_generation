{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trimesh\n",
    "!pip install fvcore iopath\n",
    "!pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch3d.io import load_obj\n",
    "import torch.nn.functional as F\n",
    "from pytorch3d.structures import Pointclouds\n",
    "import os\n",
    "import open3d as o3d\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBJDataset(Dataset):\n",
    "    def __init__(self, csv_file, obj_dir, transform=None):\n",
    "        # Load CSV with measurements\n",
    "        self.measurements = pd.read_csv(csv_file)\n",
    "        self.obj_dir = obj_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Print the columns for debugging\n",
    "        #print(\"Columns in CSV file:\", self.measurements.columns.tolist())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.measurements)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Extract relevant fields from the row\n",
    "        row = self.measurements.iloc[idx]\n",
    "        processor = row['Processor']\n",
    "        subject = row['Subject']\n",
    "        measuring_station = row['Measuring station']\n",
    "        # Construct the search prefix for the avatar file\n",
    "        file_prefix = (f\"{subject}_R1S1_{measuring_station}_{processor}\" \n",
    "                       if \"SizeStream\" in processor and \"SS20\" in measuring_station else \n",
    "                       f\"{subject}_R1_{measuring_station}_{processor}\")\n",
    "\n",
    "        # Search for the file starting with the file_prefix in the obj_dir\n",
    "        avatar_file_name = None\n",
    "        for file in os.listdir(self.obj_dir):\n",
    "            if file.startswith(file_prefix) and file.endswith(\".obj\"):\n",
    "                avatar_file_name = file\n",
    "                break\n",
    "        \n",
    "        if avatar_file_name is None:\n",
    "            raise FileNotFoundError(f\"No .obj file found for index {idx} with prefix {file_prefix}\")\n",
    "\n",
    "        # Load the .obj file\n",
    "        obj_path = os.path.join(self.obj_dir, avatar_file_name)\n",
    "        verts, faces, _ = load_obj(obj_path)\n",
    "        pointcloud = Pointclouds(points=[verts])\n",
    "\n",
    "        measurement_cols = [\n",
    "            'Neck girth', 'Back neck point to waist', 'Upper arm girth R',\n",
    "            'Upper arm girth L', 'Back neck point to wrist R', \n",
    "            'Back neck point to wrist L', 'Across back shoulder width', \n",
    "            'Bust girth', 'Waist girth', 'Hip girth', \n",
    "            'Thigh girth R', 'Thigh girth L', 'Total crotch length', \n",
    "            'Inside leg height', 'gendre'\n",
    "        ]\n",
    "\n",
    "        # Check for missing columns\n",
    "        missing_cols = [col for col in measurement_cols if col not in self.measurements.columns]\n",
    "        if missing_cols:\n",
    "            raise KeyError(f\"The following columns are missing in the DataFrame: {missing_cols}\")\n",
    "\n",
    "        # Extract measurements\n",
    "        measurements = row[measurement_cols]\n",
    "\n",
    "        # Convert categorical 'gendre' to numerical (1 for Male, 0 for Female)\n",
    "        #measurements['gendre'] = measurements['gendre'].replace({'Male': 1, 'Female': 0})\n",
    "        measurements = measurements.replace({'Male': 1, 'Female': 0})\n",
    "\n",
    "        # Ensure only numeric values are included and convert to float\n",
    "        try:\n",
    "            measurements = measurements.astype('float').values\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting measurements at index {idx}: {e}\")\n",
    "            measurements = np.zeros(len(measurements))  # Use a zero vector or other handling\n",
    "\n",
    "        # Package the pointcloud and measurements in a sample\n",
    "        sample = {'pointcloud': pointcloud.points_packed(), \n",
    "                  'measurements': torch.tensor(measurements, dtype=torch.float)}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_pointclouds(pointclouds_list):\n",
    "    max_points = 10000  # Max number of points across the dataset\n",
    "    padded_pointclouds = [F.pad(pc, (0, 0, 0, max_points - pc.shape[0]), \"constant\", 0) for pc in pointclouds_list]\n",
    "    return torch.stack(padded_pointclouds)\n",
    "\n",
    "# Custom collate function for DataLoader\n",
    "def custom_collate(batch):\n",
    "    pointclouds_list = [item['pointcloud'] for item in batch]\n",
    "    measurements_list = [item['measurements'] for item in batch]\n",
    "    padded_pointclouds = pad_pointclouds(pointclouds_list)\n",
    "    measurements = torch.stack(measurements_list)\n",
    "    return {'pointcloud': padded_pointclouds, 'measurements': measurements}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = '/kaggle/input/ieee-dataset/data IEEE/Body Measurements_output_modified2.csv'\n",
    "obj_dir_path = '/kaggle/input/ieee-dataset/data IEEE/3D_AVATARS'\n",
    "obj_dataset = OBJDataset(csv_file=csv_file_path, obj_dir=obj_dir_path)\n",
    "data_loader = DataLoader(obj_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CGAN model creation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_points, measurement_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(measurement_dim, 512),\n",
    "            nn.GroupNorm(32, 512),  # 32 groups\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.GroupNorm(32, 1024),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.GroupNorm(32, 2048),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.GroupNorm(32, 4096),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, num_points * 3),\n",
    "            nn.Tanh()  # Output between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, measurements):\n",
    "        x = self.fc1(measurements)\n",
    "        pointcloud = self.fc2(x).view(-1, self.num_points, 3)\n",
    "        return pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_points, measurement_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1_pointcloud = nn.Sequential(\n",
    "            nn.Linear(num_points * 3, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc1_measurements = nn.Sequential(\n",
    "            nn.Linear(measurement_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024 + 512, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()  # Output a probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, pointcloud, measurements):\n",
    "        pointcloud_flat = pointcloud.view(pointcloud.size(0), -1)\n",
    "        pc_features = self.fc1_pointcloud(pointcloud_flat)\n",
    "        meas_features = self.fc1_measurements(measurements)\n",
    "        combined_features = torch.cat((pc_features, meas_features), dim=1)\n",
    "        return self.fc2(combined_features)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function for cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_loss(discriminator, real_pc, fake_pc, real_measurements):\n",
    "    # Adversarial loss\n",
    "    real_preds = discriminator(real_pc, real_measurements)\n",
    "    fake_preds = discriminator(fake_pc, real_measurements.detach())\n",
    "    \n",
    "    real_loss = F.binary_cross_entropy(real_preds, torch.ones_like(real_preds))\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, torch.zeros_like(fake_preds))\n",
    "    \n",
    "    return real_loss + fake_loss\n",
    "\n",
    "# Reconstruction + Adversarial Loss for Generator\n",
    "def generator_loss(discriminator, fake_pc, real_pc, measurements):\n",
    "    fake_preds = discriminator(fake_pc, measurements)\n",
    "    adv_loss = F.binary_cross_entropy(fake_preds, torch.ones_like(fake_preds))\n",
    "    \n",
    "    # Chamfer loss for point cloud similarity\n",
    "    chamfer_loss, _ = chamfer_distance(fake_pc, real_pc)\n",
    "    \n",
    "    return adv_loss + chamfer_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstructed_pointcloud_as_obj(generator, epoch, device, example_measurements, output_dir='/kaggle/working/'):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        measurements = torch.tensor(example_measurements, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "        recon_pointcloud = generator(measurements)\n",
    "        recon_pointcloud = recon_pointcloud[0].cpu().numpy()\n",
    "\n",
    "        o3d_pc = o3d.geometry.PointCloud()\n",
    "        o3d_pc.points = o3d.utility.Vector3dVector(recon_pointcloud)\n",
    "        o3d_pc.estimate_normals()\n",
    "\n",
    "        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "            o3d_pc, depth=14\n",
    "        )\n",
    "        \n",
    "        vertices_to_remove = densities < np.quantile(densities, 0.2)\n",
    "        mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "\n",
    "        obj_file_path = os.path.join(output_dir, f'reconstructed_mesh_cGAN_data1500_epoch_{epoch}.obj')\n",
    "        o3d.io.write_triangle_mesh(obj_file_path, mesh)\n",
    "        print(f'Saved .obj file at: {obj_file_path}')\n",
    "        \n",
    "        return obj_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function for cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(num_epochs, train_loader, generator, discriminator, g_optimizer, d_optimizer, device, example_measurements, checkpoint_path=None):\n",
    "    if checkpoint_path:\n",
    "        generator.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        print(f\"Loaded pretrained weights from {checkpoint_path}\")\n",
    "\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:', epoch)\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        g_total_loss = 0\n",
    "        d_total_loss = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            pointcloud = data['pointcloud'].to(device).float()\n",
    "            measurements = data['measurements'].to(device).float()\n",
    "\n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            fake_pc = generator(measurements)\n",
    "            d_loss = gan_loss(discriminator, pointcloud, fake_pc, measurements)\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            d_total_loss += d_loss.item()\n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_pc = generator(measurements)\n",
    "            g_loss = generator_loss(discriminator, fake_pc, pointcloud, measurements)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            g_total_loss += g_loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch}, Generator Loss: {g_total_loss / len(train_loader)}, Discriminator Loss: {d_total_loss / len(train_loader)}')\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            save_path = f'/kaggle/working/generator_cGAN_dataIEEE_epoch_{epoch}.pth'\n",
    "            torch.save(generator.state_dict(), save_path)\n",
    "            print(f'Model saved at {save_path}')\n",
    "            save_reconstructed_pointcloud_as_obj(generator, epoch, device, example_measurements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator, discriminator, and optimizers\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(10000, 15)\n",
    "discriminator = Discriminator(10000, 15)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-5)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-5)\n",
    "\n",
    "example_measurements = [361.694,427.565,313.649,309.834,817.655,812.048,407.644,960.798,751.811,949.006,558.693,556.379,754.833,775.689,1]\n",
    "\n",
    "train_gan(182, data_loader, generator, discriminator, g_optimizer, d_optimizer, device, example_measurements)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
